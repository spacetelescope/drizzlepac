"""Code that evaluates the quality of the MVM products generated by the drizzlepac package.

Visualization of these Pandas DataFrames with Bokeh can follow the example
from:

https://programminghistorian.org/en/lessons/visualizing-with-bokeh

PUBLIC INTERFACE FOR THIS MODULE
 - build_mvm_plots(HDF5_FILE, output_basename='', display_plot=False):

python mvm_quality_graphics.py mvm_qa_dataframe.h5

"""

# Standard library imports
import argparse
import math
import os
import re
import sys

# Related third party imports
import pandas as pd
from bokeh.layouts import row, column, gridplot
from bokeh.plotting import figure, output_file, save, show
from bokeh.models import ColumnDataSource, Label, CDSView, Div

# Local application imports
from drizzlepac.haputils.pandas_utils import PandasDFReader, get_pandas_data
from drizzlepac.haputils.graph_utils import HAPFigure, build_tooltips
from stsci.tools import logutil

__taskname__ = 'mvm_quality_graphics'

MSG_DATEFMT = '%Y%j%H%M%S'
SPLUNK_MSG_FORMAT = '%(asctime)s %(levelname)s src=%(name)s- %(message)s'
log = logutil.create_logger(__name__, level=logutil.logging.NOTSET, stream=sys.stdout,
                            format=SPLUNK_MSG_FORMAT, datefmt=MSG_DATEFMT)

# ----------------------------------------------------------------------------------------------------------------------
# Module level variables
color26 = ['#1f77b4', '#393b79', '#aec7e8', '#ff7f0e', '#ffbb78', '#5254a3', '#2ca02c',
           '#98df8a', '#6b6ecf', '#d62728', '#ff9896', '#9467bd', '#c5b0d5', '#7b4173',
           '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#a55194', '#7f7f7f', '#c7c7c7',
           '#bcbd22', '#dbdb8d', '#ce6dbd', '#17becf', '#9edae5']

wcs_list = ['FIT_SVM_GAIAEDR3', 'FIT_EVM_GAIAEDR3', 'FIT_REL_GAIAEDR3', 'FIT_IMG_GAIAEDR3',
            'FIT_SVM_GAIADR2', 'FIT_EVM_GAIADR2', 'FIT_REL_GAIADR2', 'FIT_IMG_GAIADR2',
            'FIT_SVM_GAIADR1', 'FIT_EVM_GAIADR1', 'FIT_REL_GAIADR1', 'FIT_IMG_GAIADR1',
            'FIT_SVM_GSC242', 'FIT_EVM_GSC242', 'FIT_REL_GSC242', 'FIT_IMG_GSC242',
            'FIT_SVM_2MASS', 'FIT_EVM_2MASS', 'FIT_REL_2MASS', 'FIT_IMG_2MASS',
            'FIT_SVM_NONE', 'FIT_EVM_NONE', 'FIT_REL_NONE', 'FIT_IMG_NONE',
            'HSC30', 'GSC240']

# ------------------------------------------------------------------------------------------------------------


def build_mvm_plots(data_source, output_basename='', display_plot=False, log_level=logutil.logging.INFO):
    """Create all the plots for the results generated by these comparisons

    Parameters
    ----------
    data_source : str
        name of the .h5 file produced by diagnostic_json_harvester.py that holds the information to plot.

    output_basename : str
        text string that will be used as the basis for all .html files generated by this script. Unless
        explicitly specified, the default value is 'mvm_qa'. If a value is explicitly specified, the text
        string '_mvm_qa' will be automatically appended to the end of the user-specified value.

    display_plot : bool, optional
        If set to Boolean 'True', plots .html files will be automatically opened in the default web browser
        as they are generated. Unless explicitly specified, the default value is Boolean 'False', meaning
        that plots will only be written to output .html files but not displayed on-screen.

    log_level : int, optional
        The desired level of verboseness in the log statements displayed on the screen and written to the
        .log file. Default value is 20, or 'info'.

    Returns
    -------
    Nothing.
    """
    log.setLevel(log_level)
    if output_basename == '':
        output_basename = "mvm_qa"
    else:
        output_basename = "{}_mvm_qa".format(output_basename)

    # Generate overlap crossmatch plots
    try:
        build_overlap_crossmatch_plots(data_source,
                                       display_plot,
                                       output_basename=output_basename,
                                       log_level=log_level)
    except Exception:
        log.warning("Overlap crossmatch plot generation encountered a problem.")
        log.exception("message")
        log.warning("Continuing to next plot...")

    # Generate the WCS graphics
    try:
        wcs_graphics_driver(data_source, output_basename, display_plot, log_level=log_level)
    except Exception:
        log.warning("WCS comparison plot generation encountered a problem.")
        log.exception("message")
        log.warning("Continuing to next plot...")

# ------------------------------------------------------------------------------------------------------------
# Functions for generating each data plot
# -----------------------------------------------------------------------------
# WCS graphic
#


def build_overlap_crossmatch_plots(data_source, display_plot=False, output_basename='mvm_qa', log_level=logutil.logging.INFO):
    """retrieve required data and reformat the dataframe in preperation for the generation of overlap
    crossmatch plots.

    Parameters
    ----------
    data_source : str
        name of the .h5 file produced by diagnostic_json_harvester.py that holds the information to plot.

    display_plot : bool, optional.
        If set to Boolean 'True', plots .html files will be automatically opened in the default web browser
        as they are generated. Unless explicitly specified, the default value is Boolean 'False', meaning
        that plots will only be written to output .html files but not displayed on-screen.

    output_basename : str, optional.
        text string that will be used as the basis for all .html files generated by this script. Unless
        explicitly specified, the default value is 'mvm_qa'.

    log_level : int, optional
        The desired level of verboseness in the log statements displayed on the screen and written to the
        .log file. Default value is 20, or 'info'.

    Returns
    -------
    Nothing
    """
    log.setLevel(log_level)
    # lists of column titles that will be used.
    details_column_basenames = ["overlap_region_size",
                                "reference_catalog_name",
                                "comparison_catalog_name",
                                "total_reference_catalog_size",
                                "total_comparison_catalog_size",
                                "number_of_reference_sources_available_for_crossmatch",
                                "number_of_comparison_sources_available_for_crossmatch",
                                "number_of_crossmatched_sources"]

    difference_column_basenames = ["X-axis_differences",
                                   "Y-axis_differences",
                                   "On-sky_separation_(X-Y)",
                                   "On-sky_separation_(RA-Dec)"]

    stats_column_basenames = ["Non-clipped_minimum",
                              "Non-clipped_maximum",
                              "Non-clipped_mean",
                              "Non-clipped_median",
                              "Non-clipped_standard_deviation",
                              "3x3-sigma_clipped_mean",
                              "3x3-sigma_clipped_median",
                              "3x3-sigma_clipped_standard_deviation",
                              "Percent_of_all_diff_values_within_1-sigma_of_the_clipped_mean",
                              "Percent_of_all_diff_values_within_2-sigma_of_the_clipped_mean",
                              "Percent_of_all_diff_values_within_3-sigma_of_the_clipped_mean"]

    data_table_column_basename = "crossmatched_reference_X,_Y,_RA,_Dec,_and_crossmatched_comparison_-_reference_difference_values"
    data_table_colnames = ["X-Skycell",
                           "Y-Skycell",
                           "RA",
                           "DEC",
                           "X-axis differences",
                           "Y-axis differences",
                           "On-sky separation (X-Y)",
                           "On-sky separation (RA-Dec)"]

    # list of 26 hand-selected bokeh colors that will be used in the stats plots
    color_list = ["black", "blue", "brown", "fuchsia", "gold", "green", "olive", "orange", "purple",
                  "rebeccapurple", "red", "rosybrown", "royalblue", "saddlebrown", "salmon", "sandybrown",
                  "seagreen", "skyblue", "springgreen", "steelblue", "tan", "teal", "tomato", "turquoise",
                  "violet", "wheat"]

    n_layers_colname = 'gen_info.number of overlap regions present'
    num_layers = get_pandas_data(data_source, [n_layers_colname])[n_layers_colname]

    # retrieve relevant data and "restack" and rename dataframe so that all the information for each overlap
    # region is stored in discrete rows
    restacked_overlap_dataframe = pd.DataFrame()
    color_ctr = 0
    color_list_reset = False
    for df_indexname, layer_val in zip(num_layers.index.values, num_layers.values):
        for layer_ctr in range(1, layer_val + 1):
            columns_to_retrieve = []
            column_basename = "overlap_region_#{}".format(layer_ctr)
            # add "overlap details" columns
            for details_colname in details_column_basenames:
                columns_to_retrieve.append("{}_details.{}".format(column_basename, details_colname))
            # add stats columns for each difference type
            for diff_type in difference_column_basenames:
                for stats_colname in stats_column_basenames:
                    columns_to_retrieve.append("{}_{}.{}".format(column_basename, diff_type, stats_colname))
            # add all the data table columns
            for data_table_colname in data_table_colnames:
                columns_to_retrieve.append(
                    "{}_{}.{}".format(column_basename, data_table_column_basename, data_table_colname))
            overlap_dataframe = get_pandas_data(data_source, columns_to_retrieve)
            overlap_dataframe = overlap_dataframe[overlap_dataframe['gen_info.dataframe_index'] == df_indexname]
            dataframe_indexname = "{}_overlap_region_{}".format(overlap_dataframe['gen_info.dataframe_index'][0], layer_ctr)
            overlap_dataframe['gen_info.dataframe_index'] = dataframe_indexname
            col_rename_dict = {}
            for colname in columns_to_retrieve:
                col_rename_dict[colname] = colname.replace(column_basename, "overlap_region")
            overlap_dataframe = overlap_dataframe.rename(columns=col_rename_dict)
            overlap_dataframe['colormap'][0] = color_list[color_ctr]
            if color_list_reset == True:
                log.info("NOTE: There are more data points than colors defined for the statistics plots. The color assigned to '{}' is NOT unique.".format(dataframe_indexname))
            restacked_overlap_dataframe = restacked_overlap_dataframe.append(overlap_dataframe)
            color_ctr += 1
            # reset the counter so that it starts back at the first color in the list if there are more
            # data points to plot than colors in color_list.
            if color_ctr == len(color_list):
                color_list_reset = True
                color_ctr = 0
    # Sort columns alphabetically to make it more human-friendly
    restacked_overlap_dataframe = restacked_overlap_dataframe[overlap_dataframe.columns.sort_values()]
    # optionally write dataframe to .csv file.
    if log_level == logutil.logging.DEBUG:
        output_csv_filename = "testout.csv"
        if os.path.exists(output_csv_filename):
            os.remove(output_csv_filename)
        restacked_overlap_dataframe.to_csv(output_csv_filename)
        log.debug("Wrote restacked dataframe to csv file {}".format(output_csv_filename))

    # generate plots!
    generate_overlap_crossmatch_graphics(restacked_overlap_dataframe,
                                         display_plot=display_plot,
                                         output_basename=output_basename,
                                         log_level=log_level)


# ------------------------------------------------------------------------------------------------------------

def generate_overlap_crossmatch_graphics(dataframe, display_plot=False, output_basename='mvm_qa', log_level=logutil.logging.INFO):
    """Generate plots to statistically quantify the quality of the alignment of crossmatched sources in
    regions where observations from different proposal/visits overlap.

    Parameters
    ----------
    dataframe : pandas dataframe
        dataframe containing results from the overlap crossmatch(s) to plot.

    display_plot : bool, optional.
        If set to Boolean 'True', plots .html files will be automatically opened in the default web browser
        as they are generated. Unless explicitly specified, the default value is Boolean 'False', meaning
        that plots will only be written to output .html files but not displayed on-screen.

    output_basename : str, optional.
        text string that will be used as the basis for all .html files generated by this script. Unless
        explicitly specified, the default value is 'mvm_qa'.

    log_level : int, optional
        The desired level of verboseness in the log statements displayed on the screen and written to the
        .log file. Default value is 20, or 'info'.

    Returns
    -------
    Nothing
    """
    log.setLevel(log_level)
    xmatch_cds = ColumnDataSource(dataframe)
    # generate plots of x vs. y components of various stat. measures for each difference
    output = "{}_overlap_crossmatch_stats_plots".format(output_basename)
    if not output.endswith('.html'):
        output = output + '.html'
    # Set the output file immediately as advised by Bokeh.
    output_file(output)

    # Generate the graphic-specific tooltips - be mindful of the default tooltips defined in graph_utils.py
    hover_columns = ["gen_info.dataframe_index",
                     "overlap_region_details.overlap_region_size",
                     "overlap_region_details.reference_catalog_name",
                     "overlap_region_details.comparison_catalog_name",
                     "overlap_region_details.number_of_crossmatched_sources"]
    tooltips_list = ['Overlap region name',
                     'Overlap region size (pixels)',
                     'Ref. SVM catalog name',
                     'Comp. SVM catalog name',
                     'Number of crossmatched sources']
    tooltips_list_dynamic = ["X value", "Y value"]
    # hover_tips = build_tooltips(tooltips_list, hover_columns, list(range(0, len(hover_columns))))
    # Define the graphics
    plot_list = []
    # Create title text at the top of the html file
    html_title_text = Div(text="""<h1>Distribution characteristics of crossmatched sources identified in regions of overlapping observations in the MVM product</h1>""")
    plot_list.append(html_title_text)
    # Scatter plots!
    hover_columns_dynamic = ['overlap_region_X-axis_differences.Non-clipped_minimum',
                             'overlap_region_Y-axis_differences.Non-clipped_minimum']
    hover_tips = build_tooltips(tooltips_list+tooltips_list_dynamic, hover_columns+hover_columns_dynamic,
                                list(range(0, len(hover_columns)+2)))
    p0 = HAPFigure(title='Minimum difference value',
                   x_label='X minimum difference (pixels)',
                   y_label='Y minimum difference (pixels)', hover_tips=hover_tips)
    p0.build_glyph('circle',
                   x='overlap_region_X-axis_differences.Non-clipped_minimum',
                   y='overlap_region_Y-axis_differences.Non-clipped_minimum',
                   sourceCDS=xmatch_cds,
                   glyph_color='colormap',
                   legend_group='gen_info.dataframe_index')

    hover_columns_dynamic = ['overlap_region_X-axis_differences.Non-clipped_maximum',
                             'overlap_region_Y-axis_differences.Non-clipped_maximum']
    hover_tips = build_tooltips(tooltips_list+tooltips_list_dynamic, hover_columns+hover_columns_dynamic,
                                list(range(0, len(hover_columns)+2)))
    p1 = HAPFigure(title='Maximum difference value',
                   x_label='X maximum difference (pixels)',
                   y_label='Y maximum difference (pixels)', hover_tips=hover_tips)
    p1.build_glyph('circle',
                   x='overlap_region_X-axis_differences.Non-clipped_maximum',
                   y='overlap_region_Y-axis_differences.Non-clipped_maximum',
                   sourceCDS=xmatch_cds,
                   glyph_color='colormap',
                   legend_group='gen_info.dataframe_index')
    row1 = row(p0.fig, p1.fig)
    plot_list.append(row1)

    hover_columns_dynamic = ['overlap_region_X-axis_differences.Non-clipped_median',
                             'overlap_region_Y-axis_differences.Non-clipped_median']
    hover_tips = build_tooltips(tooltips_list+tooltips_list_dynamic, hover_columns+hover_columns_dynamic,
                                list(range(0, len(hover_columns)+2)))
    p2 = HAPFigure(title='Median difference value',
                   x_label='X median difference (pixels)',
                   y_label='Y median difference (pixels)', hover_tips=hover_tips)
    p2.build_glyph('circle',
                   x='overlap_region_X-axis_differences.Non-clipped_median',
                   y='overlap_region_Y-axis_differences.Non-clipped_median',
                   sourceCDS=xmatch_cds,
                   glyph_color='colormap',
                   legend_group='gen_info.dataframe_index')

    hover_columns_dynamic = ['overlap_region_X-axis_differences.Non-clipped_mean',
                             'overlap_region_Y-axis_differences.Non-clipped_mean']
    hover_tips = build_tooltips(tooltips_list+tooltips_list_dynamic, hover_columns+hover_columns_dynamic,
                                list(range(0, len(hover_columns)+2)))
    p3 = HAPFigure(title='Mean difference value',
                   x_label='X mean difference (pixels)',
                   y_label='Y mean difference (pixels)', hover_tips=hover_tips)
    p3.build_glyph('circle',
                   x='overlap_region_X-axis_differences.Non-clipped_mean',
                   y='overlap_region_Y-axis_differences.Non-clipped_mean',
                   sourceCDS=xmatch_cds,
                   glyph_color='colormap',
                   legend_group='gen_info.dataframe_index')
    row2 = row(p2.fig, p3.fig)
    plot_list.append(row2)

    hover_columns_dynamic = ['overlap_region_X-axis_differences.Non-clipped_standard_deviation',
                             'overlap_region_Y-axis_differences.Non-clipped_standard_deviation']
    hover_tips = build_tooltips(tooltips_list+tooltips_list_dynamic, hover_columns+hover_columns_dynamic,
                                list(range(0, len(hover_columns)+2)))
    p4 = HAPFigure(title='Difference standard deviation value',
                   x_label='X standard deviation difference (pixels)',
                   y_label='Y standard deviation difference (pixels)', hover_tips=hover_tips)
    p4.build_glyph('circle',
                   x='overlap_region_X-axis_differences.Non-clipped_standard_deviation',
                   y='overlap_region_Y-axis_differences.Non-clipped_standard_deviation',
                   sourceCDS=xmatch_cds,
                   glyph_color='colormap',
                   legend_group='gen_info.dataframe_index')

    hover_columns_dynamic = ['overlap_region_X-axis_differences.3x3-sigma_clipped_median',
                             'overlap_region_Y-axis_differences.3x3-sigma_clipped_median']
    hover_tips = build_tooltips(tooltips_list+tooltips_list_dynamic, hover_columns+hover_columns_dynamic,
                                list(range(0, len(hover_columns)+2)))
    p5 = HAPFigure(title='3x3 sigma-clipped median difference value',
                   x_label='X sigma-clipped median difference (pixels)',
                   y_label='Y sigma-clipped median difference (pixels)', hover_tips=hover_tips)
    p5.build_glyph('circle',
                   x='overlap_region_X-axis_differences.3x3-sigma_clipped_median',
                   y='overlap_region_Y-axis_differences.3x3-sigma_clipped_median',
                   sourceCDS=xmatch_cds,
                   glyph_color='colormap',
                   legend_group='gen_info.dataframe_index')
    row3 = row(p4.fig, p5.fig)
    plot_list.append(row3)

    hover_columns_dynamic = ['overlap_region_X-axis_differences.3x3-sigma_clipped_mean',
                             'overlap_region_Y-axis_differences.3x3-sigma_clipped_mean']
    hover_tips = build_tooltips(tooltips_list+tooltips_list_dynamic, hover_columns+hover_columns_dynamic,
                                list(range(0, len(hover_columns)+2)))
    p6 = HAPFigure(title='3x3 sigma-clipped mean difference value',
                   x_label='X sigma-clipped mean difference (pixels)',
                   y_label='Y sigma-clipped mean difference (pixels)', hover_tips=hover_tips)
    p6.build_glyph('circle',
                   x='overlap_region_X-axis_differences.3x3-sigma_clipped_mean',
                   y='overlap_region_Y-axis_differences.3x3-sigma_clipped_mean',
                   sourceCDS=xmatch_cds,
                   glyph_color='colormap',
                   legend_group='gen_info.dataframe_index')

    hover_columns_dynamic = ['overlap_region_X-axis_differences.3x3-sigma_clipped_standard_deviation',
                             'overlap_region_Y-axis_differences.3x3-sigma_clipped_standard_deviation']
    hover_tips = build_tooltips(tooltips_list+tooltips_list_dynamic, hover_columns+hover_columns_dynamic,
                                list(range(0, len(hover_columns)+2)))

    p7 = HAPFigure(title='3x3 sigma-clipped Difference standard deviation value',
                   x_label='X sigma-clipped difference standard_deviation (pixels)',
                   y_label='Y sigma-clipped difference standard_deviation (pixels)', hover_tips=hover_tips)
    p7.build_glyph('circle',
                   x='overlap_region_X-axis_differences.3x3-sigma_clipped_standard_deviation',
                   y='overlap_region_Y-axis_differences.3x3-sigma_clipped_standard_deviation',
                   sourceCDS=xmatch_cds,
                   glyph_color='colormap',
                   legend_group='gen_info.dataframe_index')
    row4 = row(p6.fig, p7.fig)
    plot_list.append(row4)

    if display_plot:
        show(column(plot_list))
    # Just save
    else:
        save(column(plot_list))
    log.info("Output HTML graphic file {} has been written.\n".format(output))

    # generate quad resid (x vs. dx, y vs. dx, x vs. dy, y vs. dy) plots for each DF row

    for dfindex, dfrow in dataframe.iterrows():
        qr_df = pd.DataFrame()
        qr_df = qr_df.append(dfrow)
        qr_cds = ColumnDataSource(qr_df)
        qr_dict = {"x": qr_cds.data['overlap_region_crossmatched_reference_X,_Y,_RA,_Dec,_and_crossmatched_comparison_-_reference_difference_values.X-Skycell'][0],
                   "y": qr_cds.data['overlap_region_crossmatched_reference_X,_Y,_RA,_Dec,_and_crossmatched_comparison_-_reference_difference_values.Y-Skycell'][0],
                   "dx": qr_cds.data['overlap_region_crossmatched_reference_X,_Y,_RA,_Dec,_and_crossmatched_comparison_-_reference_difference_values.X-axis differences'][0],
                   "dy": qr_cds.data['overlap_region_crossmatched_reference_X,_Y,_RA,_Dec,_and_crossmatched_comparison_-_reference_difference_values.Y-axis differences'][0]}
        qr_cds = ColumnDataSource(qr_dict)
        output = "{} {}_overlap_crossmatch_residuals_plots".format(output_basename, qr_df['gen_info.dataframe_index'].values[0])
        if not output.endswith('.html'):
            output = output + '.html'
        # Set the output file immediately as advised by Bokeh.
        output_file(output)
        # Define plots
        plot_list = []
        html_title_text = Div(text="""<h1>Crossmatched comparison - reference residuals:<br>{}</h1>""".format(qr_df['gen_info.dataframe_index'].values[0]))
        plot_list.append(html_title_text)
        # add descriptive info
        for detail_title, detail_value in zip(tooltips_list[1:], hover_columns[1:]):
            if detail_title in ["Overlap region size (pixels)", "Number of crossmatched sources"]:
                dv = int(qr_df[detail_value].values[0])
            else:
                dv = qr_df[detail_value].values[0]
            detail_html_text = Div(text="""<h3>{}: {}</h3>""".format(detail_title, dv))
            plot_list.append(detail_html_text)
        p1 = HAPFigure(title='X vs DX',
                       x_label="X (pixels)",
                       y_label='Delta[X] (pixels)',
                       use_hover_tips=False)
        p1.build_glyph('circle',
                       x='x',
                       y='dx',
                       sourceCDS=qr_cds)

        p2 = HAPFigure(title='X vs DY',
                       x_label="X (pixels)",
                       y_label='Delta[Y] (pixels)',
                       use_hover_tips=False)
        p2.build_glyph('circle',
                       x='x',
                       y='dy',
                       sourceCDS=qr_cds)
        row1 = row(p1.fig, p2.fig)
        plot_list.append(row1)

        p3 = HAPFigure(title='Y vs DX',
                       x_label="Y (pixels)",
                       y_label='Delta[X] (pixels)',
                       use_hover_tips=False)
        p3.build_glyph('circle',
                       x='y',
                       y='dx',
                       sourceCDS=qr_cds)

        p4 = HAPFigure(title='Y vs DY',
                       x_label="Y (pixels)",
                       y_label='Delta[Y] (pixels)',
                       use_hover_tips=False)
        p4.build_glyph('circle',
                       x='y',
                       y='dy',
                       sourceCDS=qr_cds)
        row2 = row(p3.fig, p4.fig)
        plot_list.append(row2)

        # Display and save
        if display_plot:
            show(column(plot_list))
        # Just save
        else:
            save(column(plot_list))
        log.info("Output HTML graphic file {} has been written.\n".format(output))

# ------------------------------------------------------------------------------------------------------------


def wcs_graphics_driver(storage_filename, output_base_filename='', display_plot=False,
                        log_level=logutil.logging.INFO):
    """Driver to load the data from the storage file and generate the graphics.

    Parameters
    ==========
    storage_filename : str
        Name of the storage file for the Pandas dataframe created by the harvester.

    output_base_filename : str, optional
        Base name for the HMTL file generated by Bokeh.

    display_plot : bool, optional
        Option to display the plot in addition to writing out the file.

    log_level : int, optional
        The desired level of verboseness in the log statements displayed on the screen and written to the
        .log file. Default value is 20, or 'info'.

    Returns
    =======
    Nothing
    """
    log.setLevel(log_level)

    # Retrieve the relevant dataframe columns as specified by the column_restring, as
    # well as some additional columns for context where the latter is done by default
    log.info('Retrieve Pandas dataframe from file {}.\n'.format(storage_filename))
    wcs_dataDF = get_wcs_data(storage_filename, column_restring='p\d\d\d\dx\d\dy\d\d')

    # Dictionary which defines how old column names map to new column names
    wcs_columns = {}

    # Rename the columns to abbreviated text as the graph titles further
    # document the information.
    if bool(wcs_columns):
        for old_col_name, new_col_name in wcs_columns.items():
            wcs_dataDF.rename(columns={old_col_name: new_col_name}, inplace=True)

    # Generate the WCS graphic for specific skycell layer
    generate_wcs_graphic(wcs_dataDF, output_base_filename, display_plot, log_level)


def generate_wcs_graphic(wcs_dataDF, output_base_filename='', display_plot=False,
                         log_level=logutil.logging.NOTSET):
    """Generate the graphics associated with this particular type of data.

    Parameters
    ==========
    wcs_dataDF : Pandas dataframe
        A subset of the input Dataframe consisting only of columns associated
        with the gathering of WCS data

    output_base_filename : str
        Base name for the HMTL file generated by Bokeh.

    display_plot : bool, optional
        Option to display the plot to the screen
        Default: False

    log_level : int, optional
        The desired level of verboseness in the log statements displayed on the screen and written to the
        .log file. Default: 20 or 'info'.

    Returns
    =======
    Nothing

    HTML file is generated and written to the current directory.
    """
    log.setLevel(log_level)

    # Set the output file immediately as advised by Bokeh.
    if output_base_filename == '':
        output_base_filename = 'mvm_qa_wcs'
    else:
        output_base_filename = '{}_mvm_qa_wcs'.format(output_base_filename)
    output_file(output_base_filename + '.html')

    # Suffix for the column data needed for the bar chart
    suffix = ['wcsname', 'wcs_value']

    # Gather information regarding constituents of each skycell (p####x##y##)
    # 0) Determine all the skycells in use
    # 1) Identify all layers of a skycell
    # 2) Determine number of exposures in each layer
    # 3) For each layer make a set of the WCSNAMEs
    # 4) Compute the % of exposures using each WCSNAME
    # 5) Plot as a bar chart

    # Determine all the skycell names
    column_names = [item for item in wcs_dataDF.columns if re.search('p\d\d\d\dx\d\dy\d\d.filename', item)]
    skycell_names = [item.split('.')[0] for item in column_names]
    log.info('There are {} skycell datasets.'.format(len(skycell_names)))

    # Get all the row names (dataframe index) - these are the layers of the skycell
    all_rows = wcs_dataDF.index.tolist()

    # Set up for a list of plots
    plots = []

    # Loop over the skycell names for the graphics to be generated
    for skycell in skycell_names:

        # Set up the names of the columns needed for the bar graphic
        bar_columns = [skycell + '.' + item for item in suffix]

        # Get all the layer names for just this skycell
        layer_names = [item for item in all_rows if re.search(skycell, item)]
        num_layers = len(layer_names)

        # This is a dataframe of just one skycell
        df = wcs_dataDF.loc[layer_names, bar_columns]

        # Determine the number of exposures and unique WCS names in the layer
        # row is a list of two lists, wcsnames and wcs_values
        wcsnames_all_layers = []
        layer_dict = {}
        max_num_expo = 0
        for layer in layer_names:
            wcs_dict = {}
            row = df.loc[layer].tolist()
            num_exposures = len(row[0])
            max_num_expo = num_exposures if num_exposures > max_num_expo else max_num_expo
            set_wcsnames = set(row[0])
            wcsnames_all_layers.extend(row[0])
            for item in set_wcsnames:
                # How many times is WCSNAME in the list of WCSNAMEs for this layer
                wcs_dict[item] = row[0].count(item)
            layer_dict[layer] = wcs_dict

        # Get the unique WCSNAMEs as a list
        wcsnames_all_layers = list(set(wcsnames_all_layers))

        # These machinations were done to push the WCS information into a dataframe
        # which can then be utilized by Bokeh for a vertical stacked bar graph

        # The new columns of the skycell dataframe are all the WCSNAMEs in use
        # Want to ensure the data is added to the correct row (aka layer), so add
        # a column of zeros first.
        for item in wcsnames_all_layers:
            empty_col = [0 * i for i in range(num_layers)]
            df[item] = empty_col

            # Now fill in the proper data
        for layer in layer_names:
            for item in wcsnames_all_layers:
                try:
                    df.loc[layer, item] = layer_dict[layer][item]
                # This layer just did not have any exposures with this WCSNAME
                except KeyError:
                    pass

        # Create a new column using the index values -- seems to be easier to use
        df['LAYER_NAME'] = df.index.str[24:-4]
        grouped = df.groupby('LAYER_NAME')[wcsnames_all_layers].sum()

        # Setup the source of the data to be plotted so the axis variables can be
        # referenced by column name in the Pandas dataframe
        sourceCDS = ColumnDataSource(grouped)
        layers = sourceCDS.data['LAYER_NAME'].tolist()

        # Map the WCSNAMEs to specific colors so any particular WCSNAME will always have
        # the same color
        dict_wcs_color = dict(zip(wcs_list, color26))
        colors = [dict_wcs_color.get(item) for item in wcsnames_all_layers]

        # The graphic
        p = figure(x_range=layers)
        p.xaxis.major_label_orientation = math.pi / 4
        p.title.text = 'Sky Cell ' + skycell.upper()
        p.xaxis.axis_label = 'Sky Cell Layer'
        p.yaxis.axis_label = 'Count of WCS Names'
        p.x_range.range_padding = 0.1
        p.y_range.end = max_num_expo + (0.3 * max_num_expo)
        if p.y_range.end % 2 > 0:
            p.y_range.end += 1

        legend = wcsnames_all_layers
        p.vbar_stack(stackers=wcsnames_all_layers,
                     x='LAYER_NAME', source=sourceCDS,
                     legend_label=wcsnames_all_layers,
                     width=0.5, color=colors)
        p.legend.location = 'top_left'

        plots.append(p)

    # Setup the grid to have two columns and multiple rows as it is not know a priori
    # how many datasets will be processed
    grid = gridplot(plots, ncols=2)

    # Display and save
    if display_plot:
        show(grid)
        log.info("Output HTML graphic file {} displayed in browser and has been written.\n".format(
            output_base_filename + ".html"))
    # Just save
    else:
        save(grid)
        log.info("Output HTML graphic file {} has been written.\n".format(output_base_filename + ".html"))


# -----------------------------------------------------------------------------
# General Utility functions for plotting
#


def get_wcs_data(storage_filename, wcs_columns=None, column_restring='', log_level=logutil.logging.NOTSET):
    """Load the harvested data, stored in a storage file, into local arrays.

    Parameters
    ==========
    storage_filename : str
        Name of the storage file for the Pandas dataframe created by the harvester.

    wcs_columns : dict
        Dictionary of original column names (keys) as stored in the Pandas dataframe
        and the corresponding simple name (values) which is often more practical for use.

    column_restring : str
        Substring to use to match as a regular expression against all available
        column names. This parameter is ONLY used in the instance column_names
        is None.

    log_level : int, optional
        The desired level of verboseness in the log statements displayed on the screen and written to the
        .log file. Default: 20 or 'info'.

    Returns
    =======
    wcs_dataDF : Pandas dataframe
        Dataframe which is a subset of the input Pandas dataframe which
        consists of only the requested columns and rows, as well as any columns provided
        by pandas_utils for free.

    Note: This routine is different from the nominal get_pandas_data() in that it tries to
    compensate in case on the of requested columns (apriori or aposteriori) is missing.
    """
    log.setLevel(log_level)

    # Instantiate a Pandas Dataframe Reader (lazy instantiation)
    df_handle = PandasDFReader(storage_filename, log_level=log_level)

    # Get the relevant column data
    wcs_dataDF = df_handle.get_columns_HDF5(column_restring=column_restring)

    # If no dataframe were returned, there was a KeyError because columns were
    # not present in the original dataframe versus the columns contained NaNs.
    if wcs_dataDF.empty:
        log.critical("Critical columns not found in storage Pandas dataframe: {}.\n".format(
            storage_filename))
        sys.exit(1)

    log.info("WCS data has been retrieved from the storage Pandas dataframe: {}.\n".format(storage_filename))

    return wcs_dataDF

# ------------------------------------------------------------------------------------------------------------


if __name__ == "__main__":
    """Simple command-line interface. That is all.
    """
    # process command-line inputs with argparse
    parser = argparse.ArgumentParser(description='Generate MVM quality assessment plots based on information'
                                                 ' stored in the user-specified .h5 file.')
    parser.add_argument('input_filename',
                        help='Input .h5 file produced by diagnostic_json_harvester.py that holds the '
                             'information to plot.')
    parser.add_argument('-d', '--display_plot', required=False, action='store_true',
                        help='If specified, plots will be automatically opened in the default web browser as '
                             'they are generated. Otherwise, .html plot files will be generated but not '
                             'opened.')
    parser.add_argument('-l', '--log_level', required=False, default='info',
                        choices=["critical", "error", "warning", "info", "debug", "notset"],
                        help='The desired level of verboseness in the log statements displayed on the screen '
                             'and written to the .log file.')
    parser.add_argument('-o', '--output_basename', required=False, default='',
                        help='Base name for the HMTL file generated by Bokeh.')
    user_args = parser.parse_args()

    # verify that input file exists
    if not os.path.exists(user_args.input_filename):
        err_msg = "File {} doesn't exist.".format(user_args.input_filename)
        log.critical(err_msg)
        sys.exit(err_msg)

    # set up logging
    log_dict = {"critical": logutil.logging.CRITICAL,
                "error": logutil.logging.ERROR,
                "warning": logutil.logging.WARNING,
                "info": logutil.logging.INFO,
                "debug": logutil.logging.DEBUG,
                "notset": logutil.logging.NOTSET}
    log_level = log_dict[user_args.log_level]
    log.setLevel(log_level)

    # execute plot generation!
    build_mvm_plots(user_args.input_filename, output_basename=user_args.output_basename,
                    display_plot=user_args.display_plot, log_level=log_level)
